{
  "hash": "841c3aff0d371fb516f4d1633cb5207e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Intraclass Correlation Coefficient 이해하기\"\ndescription: |\n  Intraclass Correlation Coefficient에 대해 정리하였습니다.\ncategories:\n  - statistics\nauthor: \n  name: Sungho Choi\n  url: https://github.com/scacola\ndate: \"03-31-2025\"\nimage: icc.png\nformat: \n  html: \n    toc-depth: 3\n    toc-expand: true\n    toc-location: left\n    toc-title: \"Intraclass Correlation Coefficient 이해하기\"\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n# ICC는 무엇인가\n\n[Intraclass Correlation Coefficient\n(ICC)](https://en.wikipedia.org/wiki/Intraclass_correlation)는 집단으로\n구성된 단위들에 대해 수치 측정값이 주어졌을 때, 동일한 집단 내 단위들이\n**서로 얼마나 유사한지**를 나타내는 기술 통계량이다.\n\nICC는 일반적인 상관계수와 달리 **짝지어진 관측값**이 아니라, 그룹으로\n구성된 데이터에 대해 계산된다는 점에서 차이가 있다.\n\n# 초기의 ICC\n\n초기의 ICC 연구는 **짝을 이루는 측정값**에 초점을 맞췄으며, 처음 제안된\nICC 통계량은 **Pearson 상관계수**를 수정한 형태였다.\n\n## 초기 ICC의 정의\n\nRonald Fisher가 제안한 초기 ICC는 다음과 같다.\n\n$$\nr = \\sum_{n=1}^{N} \\frac{(x_{n,1} - \\bar{x})(x_{n,2} - \\bar{x})}{N}\n$$\n\n-   데이터셋은 $N$개의 짝으로 구성됨\n-   각 개체 $n$에 대해 두 개의 측정값 $(x_{n,1} , x_{n,2})$가 존재함\n-   $\\bar{x}$는 전체 데이터의 평균 $$\n    \\bar{x} = \\frac{1}{2N} \\sum_{n=1}^{N} (x_{n,1} + x_{n,2})\n    $$\n-   $s^2$은 전체 데이터의 분산 $$\n    s^2 = \\frac{1}{2N} \\left\\{ \\sum_{n=1}^{N} (x_{n,1} - \\bar{x})^2 + \\sum_{n=1}^{N} (x_{n,2} - \\bar{x})^2 \\right\\}\n    $$\n\n|    r 값 범위     | 신뢰도의 정도  |\n|:----------------:|:--------------:|\n|     r ≤ 0.00     |      Poor      |\n| 0.00 \\< r ≤ 0.20 |     Slight     |\n| 0.20 \\< r ≤ 0.40 |      Fair      |\n| 0.40 \\< r ≤ 0.60 |    Moderate    |\n| 0.60 \\< r ≤ 0.80 |  Substantial   |\n| 0.80 \\< r ≤ 1.00 | Almost Perfect |\n\n## Pearson 상관계수와 ICC의 차이점\n\nPearson 상관계와 ICC의 핵심 차이는 데이터의 평\n\n## 3개 이상의 값을 가진 그룹에서의 ICC\n\n데이터셋이 각 그룹당 3개의 측정값을 가지는 경우, ICC는 다음과 같이\n확장된다. $$\nr = \\frac{1}{3N s^2} \\sum_{n=1}^{N} \\left\\{ \n(x_{n,1} - \\bar{x})(x_{n,2} - \\bar{x}) + \n(x_{n,1} - \\bar{x})(x_{n,3} - \\bar{x}) + \n(x_{n,2} - \\bar{x})(x_{n,3} - \\bar{x}) \n\\right\\}\n$$\n\n-   $\\bar{x}$는 전체 평균 $$\n    \\bar{x} = \\frac{1}{3N} \\sum_{n=1}^{N} (x_{n,1} + x_{n,2} + x_{n,3})\n    $$\n-   $s^2$는 전체 분산 $$\n    s^2 = \\frac{1}{3N} \\left\\{ \n    \\sum_{n=1}^{N} (x_{n,1} - \\bar{x})^2 + \n    \\sum_{n=1}^{N} (x_{n,2} - \\bar{x})^2 + \n    \\sum_{n=1}^{N} (x_{n,3} - \\bar{x})^2 \n    \\right\\}\n    $$ 여기서, 그룹의 크기(K)가 커질수록, 계산 과정에서 고려해야 할\n    교차항의 수도 증가한다.\n\n위 공식을 일반화하면 다음과 같아진다. $$\nr = \\frac{K}{K-1} \\cdot \\frac{1}{Ns^2} \\sum_{n=1}^{N} (\\bar{x}_n - \\bar{x})^2 - \\frac{1}{K-1}\n$$\n\n-   $K$는 그룹당 데이터 개수\n-   $\\bar{x_n}$는 $n$번째 그룹의 평균\n\n$K=3$을 대입하면 위 공식과 완벽히 같아진다. 위 공식에 따르면, ICC값은\n항상 $\\frac{-1}{K-1}$이상의 값을 가진다는 것을 알 수 있다. 따라서 ICC는\n항상 $-1 \\leq r \\leq 1$의 범위 안에서 존재하지만, **데이터 개수(**$K$)가\n많아질 수록 음수로 나올 가능성이 줄어든다.\n\n또한 충분히 큰 $K$에 대해서, 다음과 같이 근사할 수도 있다. $$\nr = \\frac{K}{K-1} \\cdot \\frac{1}{Ns^2} \\sum_{n=1}^{N} (\\bar{x}_n - \\bar{x})^2\n$$\n\n## ICC의 해석 및 한계점\n\nICC는 총 분산 중에서 그룹 간 변동이 차지하는 비율로 해석할 수 있다.\n\n이상적인 데이터에서는 ICC 값이 0\\~1 사이에 있어야 하지만, 실제 샘플\n데이터에서는 음수 값이 나올 수도 있다. 이는 Ronald Fisher가 ICC를\n편향되지 않은 추정량으로 설계했기 때문이다. 따라서 모집단에서 ICC가 0일\n경우, 표본 데이터에서는 음수 값이 나올 수 있다.\n\n# 모던 ICC\n\n초기 ICC는 ANOVA(분산 분석) 기반의 접근 방식으로 시작되었으나, 이후\n**랜덤 효과 모형(Random Effects Model)**을 통해 발전하였다.\n\n## 랜덤 효과 모형에서의 ICC\n\n모던 ICC는 다음과 같은 one-way random effects 모형에서 정의된다. $$\nY_{ij} = \\mu + \\alpha_j + \\varepsilon_{ij}\n$$\n\n-   $Y_{ij}$는 $j$번째 그룹의 $i$번째 측정값\n-   $\\mu$는 모집단 전체의 평균\n-   $\\alpha_j$는 그룹 $j$에 해당하는 랜덤효과\n-   $\\varepsilon_{ij}$는 오차항\n\n## 모던 ICC의 공식\n\n모던 ICC는 다음과 같이 정의된다. $$\nICC = \\frac{\\sigma^2_{\\alpha}}{\\sigma^2_{\\alpha} + \\sigma^2_{\\varepsilon}}\n$$\n\n분자$(\\sigma^2_{\\alpha})$는 그룹간 분산을 의미하고,\n분모$(\\sigma^2_{\\alpha}+\\sigma^2_{\\varepsilon})$은 전체 분산을 의미한다.\n\n즉 ICC는 전체 변동에서 그룹간 변동이 차지하는 비율이 된다. 따라서\nICC값이 클 수록 같은 그룹 내에서 값들이 더 유사하다는 것을 알 수 있다.\n\n**증명**\n\n$Y_{ij} = \\mu + \\alpha_j + \\varepsilon_{ij}$에서\n$\\alpha_i \\sim N(0, \\sigma^2_{\\alpha})$,\n$\\epsilon_{ij} \\sim N(0, \\sigma^2_{\\varepsilon})$이고 $\\alpha_i$와\n$\\varepsilon_{ij}$은 서로 독립이다.\n\n$Var(Y_{ij}) = \\sigma^2_{\\varepsilon} + \\sigma^2_{\\alpha^2}$\n\n\n\n```{=tex}\n\\begin{align}\nCov(Y_{ij}, Y_{ik}) &= Cov(\\mu + \\alpha_{i} + \\varepsilon_{ij}, \\mu + \\alpha_{i} + \\varepsilon_{ik})\\\\\n  &= Cov(\\alpha_i + \\varepsilon_{ij},\\alpha_i + \\varepsilon_{ik}) \\\\\n  &= Cov(\\alpha_i , \\alpha_i) + Cov(\\alpha_i, \\varepsilon_{ik}) + Cov(\\varepsilon_{ij}, \\alpha_i) + Cov(\\varepsilon_{ij}, \\varepsilon_{ik}) \\\\\n  &= Var(\\alpha_i) = \\sigma^2_\\alpha\n\\end{align}\n```\n\n\n## 모던 ICC의 장점\n\n-   항상 0 이상이다\n    -   초기 ICC는 표본에서 음수값이 나올 수 있었음\n-   ANOVA와 결합 가능하다 $\\rightarrow$ 샘플 개수가 달라도 적용 가능하다\n    -   초기 ICC는 같은 크기의 그룹을 가정함\n    -   하지만 ANOVA 기반 ICC는 데이터 개수가 달라고 계산 가능\n-   공변량을 포함할 수 있다\n    -   공변량을 통제한 후에도 같은 그룹 내에서 얼마나 유사한지 평가할\n        수 있음\n\n## 모던 ICC의 한계점\n\n-   샘플 ICC가 실제 모집단 ICC보다 클 가능성이 높다\n    -   초기 ICC는 편향되지 않은 추정량임\n    -   모던 ICC는 항상 0 이상이므로, 모집단의 ICC가 정확히 0일 때에도\n        샘플에서 ICC가 0보다 크게 나올 가능성이 있음\n    -   즉, 양의 편향을 가짐\n-   여러 종류의 ICC가 존재$\\rightarrow$어떤 ICC를 사용할지 논란이 된다\n    -   연구자마다 다른 ICC 통계량을 사용하며, 각 방법이 서로 다른\n        결과를 낼 수 있음\n    -   특정 연구 목적에 적합한 ICC를 신중하게 선택해야 함\n\n# ICC의 체계화\n\n## Shrout & Fleiss (1979)\n\nShrout & Fleiss는 초기의 ICC를 체계적으로 분류하였다. 3가지 모델\n유형(Model 1, 2, 3), 2가지 측정 방식(1: single, k: 평균)으로 분류하여 총\n6가지 유형의 ICC를 정의하였다.\n\n**모델 종류**\n\n-   one-way random\n    -   피험자 간의 변동만을 고려하는 모형\n    -   피험자 간의 차이에 대한 평가지의 일치도를 평가할 때 사용함\n    -   평가자의 효과는 고려하지 않고, 단순히 피험자 간의 일관성을\n        평가할 때 사용함\n-   two-way random\n    -   피험자 간 변동뿐만이 아니라, 평가자 간의 변동도 고려하는 모형\n    -   동일한 피험자에 대해 평가한 결과가 얼마나 일치하는지, 평가자들\n        간의 평가 결과가 얼마나 일관성 있는 지를 평가할 때 사용함\n-   two-way mixed\n    -   피험자 간의 변동과 평가자 간의 변동을 고려하는 모형\n    -   특정 평가자들이 고정되어 있을 때, 피험자 간의 일치도를 평가하는\n        데 사용함\n\n**측정방식**\n\n-   단일 측도(single)\n    -   평가자 간에 얼마나 차이가 있는지 확인\n    -   각 평가자에 의해 한 번의 측정이 일어난 경우\n-   평균 측도(average)\n    -   평균값과 얼마나 차이가 있는지 확인\n    -   각 평가자에 의해 여러 번 측정이 일어난 경우\n\n## McGraw & Wong (1996)\n\nMcGraw & Wong은 Shrout & Fleiss의 체계를 확장하여 총 10가지 ICC 형태를\n정의하였다. 다음과 같은 총 3가지의 분류 기준을 제시하였다.\n\n**모델 종류**\n\n-   one-way random\n\n-   two-way random\n\n-   two-way mixed\n\n**측정방식**\n\n-   단일 측도(single)\n\n-   평균 측도(average)\n\n**정의(Definition Agreement)**\n\n-   일치도(consistency)\n    -   상대적 순위/경향이 일치하는지를 의미\n    -   평가자 간의 체계적인 차이는 무시하고, 변동성만 분석\n    -   포함하는 오차 : 우연한 변동\n    -   사용 상황 : 평가자가 고정되어 있고, 상대적 순위가 중요한 경우\n-   절대합의도(absolute agreement)\n    -   두 평가자의 결과가 완전히 같은지를 의미\n    -   평가자 간의 체계적인 차이까지도 고려\n    -   포함하는 오차 : 우연한 변동, 평가자 간 편향\n    -   사용 상황 : 정량적 측정이 실제 절대값의 일치도를 요구하는 경우\n\n## ICC 분류\n\n아래의 표는 Shrout & Fleiss와 McGraw & Wong의 기준에 따라 ICC를 정리한\n것이다.\n\n|                            McGraw and Wong                            | Shrout and Fleiss |                    Formulas for Calculating ICC                    |\n|:--------------------------:|:---------------:|:-------------------------:|\n|  One-way random effects, absolute agreement, single rater/measurment  |     ICC(1,1)      |               $\\frac{MS_R - MS_W}{MS_R +(k+1)MS_W}$                |\n|     Two-way random effects, consistency, single rater/measurment      |        \\-         |               $\\frac{MS_R - MS_E}{MS_R +(k-1)MS_E}$                |\n|  Two-way random effects, absolute agreement, single rater/measurment  |     ICC(2,1)      | $\\frac{MS_R - MS_E}{MS_R +(k-1)MS_E + \\frac{k}{n} (MS_C - MS_E )}$ |\n|     Two-way mixed effects, consistency , single rater/measurment      |     ICC(3,1)      |               $\\frac{MS_R - MS_E}{MS_R +(k-1)MS_E}$                |\n|  Two-way mixed effects, absolute agreement, single rater/measurment   |        \\-         | $\\frac{MS_R - MS_E}{MS_R +(k-1)MS_E + \\frac{k}{n} (MS_C - MS_E )}$ |\n| One-way random effects, absolute agreement, multiple rater/measurment |     ICC(1,k)      |                     $\\frac{MS_R - MS_W}{MS_R}$                     |\n|    Two-way random effects, consistency, multiple rater/measurment     |        \\-         |                     $\\frac{MS_R - MS_E}{MS_R}$                     |\n| Two-way random effects, absolute agreement, multiple rater/measurment |     ICC(2,k)      |         $\\frac{MS_R - MS_E}{MS_R + \\frac{MS_C -MS_E}{n}}$          |\n|     Two-way mixed effects, consistency, multiple rater/measurment     |     ICC(3,k)      |                     $\\frac{MS_R - MS_E}{MS_R}$                     |\n| Two-way mixed effects, absolute agreement, multiple rater/measurment  |        \\-         |         $\\frac{MS_R - MS_E}{MS_R + \\frac{MS_C -MS_E}{n}}$          |\n\n-   $k$ : 평가자 수\n-   $n$ : 피험자 수\n-   $MS_R$ : mean square for rows\n-   $MS_W$ : mean square for residual sources of variance\n-   $MS_E$ : mean square for error\n-   $MS_C$ : mean square for columns\n\n## One-way 모델에서 Consistency가 정의 되지 않는 이유\n\nOne-way random model은 평가자 효과를 모델에 포함하지 않기 때문이다.\nOne-way 모델에서는 오직 피험자 간 차이만 고려하기 때문에 평가자 간\n차이가 분산 구조에서 빠져있다. 따라서 평가자 간 일관성을 측정할 수 없다.\n결과적으로 One-way 모델은 \"Agreement\"는 가능하지만 \"Consistency\"는\n정의할 수 없다.\n\n## ICC 방식을 정하는 법\n\n![ICC 방식을 정하는 과정](img/icc.figure.png)\n\n# ICC R 실습\n\n\n```\n{r}\ninstall.packages(\"irr\")\n\nlibrary(irr)\n\nratings <- data.frame(\n  Rater1 = c(4, 5, 3, 4, 2),\n  Rater2 = c(5, 5, 4, 4, 3),\n  Rater3 = c(4, 5, 3, 5, 2)\n)\n\nresult <- icc(ratings, model = \"twoway\", type = \"agreement\", unit = \"single\")\n\nprint(result)\n```",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}